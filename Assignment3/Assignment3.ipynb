{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9a42d3e",
   "metadata": {
    "id": "a9a42d3e"
   },
   "source": [
    "## AISE4010- Assignment3 - Time Series Classification using TCN and Transformer + Hyperparameter Tuning\n",
    "\n",
    "## Grade: 100 points\n",
    "\n",
    "### Instructions\n",
    "\n",
    "#### Follow These Steps before submitting your assignment\n",
    "\n",
    "1. Complete the notebook.\n",
    "\n",
    "2. Make sure all plots have axis labels.\n",
    "\n",
    "3. Once the notebook is complete, `Restart` your kernel by clicking 'Kernel' > 'Restart & Run All'.\n",
    "\n",
    "4. Fix any errors until your notebook runs without any problems.\n",
    "\n",
    "5. Submit one completed notebook for the group to OWL by the deadline.\n",
    "\n",
    "6. Make sure to reference all external code and documentation used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f0f3d3",
   "metadata": {
    "id": "b5f0f3d3"
   },
   "source": [
    "### Dataset\n",
    "\n",
    "The dataset is a sample of 46 satellite images, collected in 2006, located in southwestern France near Toulouse. It\n",
    "is a 24 km Ã— 24 km area and the dataset uses 3 output classes (2 available) for arable soil classification based on the following paper: https://arxiv.org/pdf/1811.10166.\n",
    "\n",
    "You will be using helper functions below to prepare it for deep learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03632d8e-12d3-4200-a8fa-54b9d3e6ac98",
   "metadata": {
    "id": "03632d8e-12d3-4200-a8fa-54b9d3e6ac98"
   },
   "outputs": [],
   "source": [
    "# Call this helper method by passing in the names of the provided training and test sets' files.\n",
    "def read_SITS_data(name_file):\n",
    "    data = pd.read_table(name_file, sep=',', header=None)\n",
    "\n",
    "    y_data = data.iloc[:,0]\n",
    "    y = np.asarray(y_data.values, dtype='uint8')\n",
    "    y[y>1] = 0\n",
    "\n",
    "    polygonID_data = data.iloc[:,1]\n",
    "    polygon_ids = polygonID_data.values\n",
    "    polygon_ids = np.asarray(polygon_ids, dtype='uint16')\n",
    "\n",
    "    X_data = data.iloc[:,2:]\n",
    "    X = X_data.values\n",
    "    X = np.asarray(X, dtype='float32')\n",
    "\n",
    "    return  X, polygon_ids, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4517e085-607d-4113-a9e0-de4864603bb9",
   "metadata": {
    "id": "4517e085-607d-4113-a9e0-de4864603bb9"
   },
   "outputs": [],
   "source": [
    "def custom_feature_scaling(train, test):\n",
    "    min_per = np.percentile(train, 2, axis=(0,1))\n",
    "    max_per = np.percentile(train, 100-2, axis=(0,1))\n",
    "\n",
    "    new_train = (train-min_per)/(max_per-min_per)\n",
    "    new_test = (test-min_per)/(max_per-min_per)\n",
    "\n",
    "    return new_train, new_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d33d79a",
   "metadata": {
    "id": "3d33d79a"
   },
   "source": [
    "### Question 1 - Data Preprocessing (15%)\n",
    "- Q1.1 Call \"read_SITS_data()\" for the training set and store the results as X_train, polygon_ids_train, and y_train.\n",
    "- Q1.2 Call \"read_SITS_data()\" above for the test set and store the results as X_test, polygon_ids_test, and y_test.\n",
    "- Q1.3 Reshape the training and test sets.\n",
    "  - Each set must be reshaped into a 3-D array. The first dimension will be the number of rows of the original set. The second dimension will be int(x / 3), where x is the number of columns of the original set and int() is a casting function. The third dimension will be 3 (number of channels).\n",
    "- Q1.4 Call \"custom_feature_scaling()\" with the training and test sets. Save the results as the final sets for use.\n",
    "- Q1.5 How many entries are in the training set? How many time steps are in each entry? How many features are there for each time step? How many labels for each entry?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cfb1ce-0c21-4243-b221-f8d06145bf3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f3b85f41",
   "metadata": {
    "id": "f3b85f41"
   },
   "source": [
    "*Write your Answer to Q1.5 here:*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d501e5c3",
   "metadata": {
    "id": "d501e5c3"
   },
   "source": [
    "### Question2 - Temporal Convolutional Network\n",
    "- Q2.1 Create a Sequential model for classification. The model should have a TCN layer of size 64, a fully connected layer of size 256, a dropout of 0.3, and a fully connected output layer with Softmax activation (Hint: the logits axis should be on 0). Train the model using the provided dataset for 20 epochs. Use the batch_size of 32, and ADAM optimizer. Print the model summary.\n",
    "- Q2.2 Train the model with the same parameters, print the model summary and evaluate the model's accuracy on the test set. Print the accuracy.\n",
    "- Q2.3 Why do we use the Softmax activation on the output layer? In what scenarios does this contrast to using ReLU instead?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984215d3-9331-4d76-a970-ef3208bd17de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "55549340",
   "metadata": {
    "id": "55549340"
   },
   "source": [
    "*Write your Answer to Q2.3 Here:*\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf4f585",
   "metadata": {
    "id": "4cf4f585"
   },
   "source": [
    "### Question 3 - Transformer Model\n",
    "- Q3.1 Create a transformer encoder block. It should use MultiHeadAttention for residual connection. The projection layers can be two Conv1D layers, based on number of feed forward dimensions and with kernel sizes of 1.\n",
    "- Q3.2 Define the model. It should have 4 encoder blocks, each with 256 heads and feed forward dimensions of 4. Add a flatten layer, then a fully connected layer of size 2 and a fully connected output layer.\n",
    "- Q3.3 Print the model summary, train the model using 50 epochs and a batch size of 32. Evaluate the model accuracy on the test set and print it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e16ef6e-2305-4f0c-846f-90e1fce36760",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c3836425",
   "metadata": {
    "id": "c3836425"
   },
   "source": [
    "### Question 4 - Hyperparameter Tuning\n",
    "- Q4.1 Define a search space for the number of neurons in the fully connected layer that follows the flatten layer. The lower bound should be 2, the upper bound should be 16, and it should search every other value in between. Also have the tuner decide whether or not a dropout layer of 0.3 should be added after the aforementioned layer.\n",
    "- Q4.2 Using GridSearch, search for the best hyperparameters with respect to accuracy over 50 epochs.\n",
    "- Q4.3 Using the best hyperparameters, rebuild the model and print the model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb0bcdc-45d7-44ba-bbef-50be40c75641",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18bb2822",
   "metadata": {
    "id": "18bb2822"
   },
   "source": [
    "### Question 6 - Discussion (5%)\n",
    "- Q6.1 Indicate other hyperparameters relevant to transformers that can be tuned.\n",
    "- Q6.2 What are the advantages and disadvantages of using GridSearch for finding optimal hyperparameters?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b39d8ed",
   "metadata": {
    "id": "4b39d8ed"
   },
   "source": [
    "*Write your Answer to Q6.1 and Q6.2 Here:*\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
